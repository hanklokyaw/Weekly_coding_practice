import requests
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from datetime import datetime
import os
import time
import re
import json
import moviepy.editor as mp

URL_1 = "https://www.onlineclass.com/lessons/"
URL_2 = ""
URL_3 = ""

header = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:111.0) Gecko/20100101 Firefox/111.0",
    "Accept-Language": "en-GB,en-US;q=0.9,en;q=0.8"
}

# Path to geckodriver
geckodriver_path = '/path/to/geckodriver'  # Update with your path

# for selenium web automation
# Initialize the Firefox WebDriver
driver = webdriver.Firefox()
driver.get(URL_1)

# ### get username and password input boxes path
username = driver.find_element(By.XPATH, '//*[@id="user[email]"]')
password = driver.find_element(By.XPATH, '//*[@id="user[password]"]')

### input the email id and password
username.send_keys("user@gmail.com")
password.send_keys("Password")
time.sleep(3)

### click the login button
login_btn = driver.find_element(By.XPATH,
                                """/html/body/main/div/div/article/form/div[6]/button""")
login_btn.click()
time.sleep(10)

### click the module 2 tab
login_btn = driver.find_element(By.XPATH,
                                """/html/body/div[1]/div[2]/div[2]/div/div[1]/div/nav/div/div[4]/div[7]/div[1]/div""")
login_btn.click()
time.sleep(3)

## get all titles and store into a list
# Initialize an empty list to store the extracted titles
titles = []
# Parse the HTML with BeautifulSoup
soup = BeautifulSoup(driver.page_source, 'html.parser')
# Find all divs containing the titles
title_divs = soup.find_all('div', class_=['content-item__title', '_content-item__title_nffvg8'])
# Iterate through each found div and extract the text
for title_div in title_divs:
    title_text = ''.join(title_div.strings).strip()
    titles.append(title_text)
# # Output the extracted titles
# for title in titles:
#     print(f"Title: {title}")

### check each clip tab
for clip in range (1,17):
    title_index = clip - 1
    ### click the Module 2 button
    login_btn = driver.find_element(By.XPATH,
                                    f"""/html/body/div[1]/div[2]/div[2]/div/div[1]/div/nav/div/div[4]/div[7]/div[2]/ul/li[{clip}]/a/div[2]""")
    login_btn.click()
        
    ### wait time setting
    time.sleep(3)
    
    ## use BeautifulSoup to parse HTML
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    
    ## find all iframes
    iframes = soup.find_all('iframe')
    
    ## print iframe src attribute that contains the specific path
    for iframe in iframes:
        src = iframe.get('src', '')
        
        # find the first link of iframe
        if "https://platform.thinkific.com" in src:
            print("First Iframe URL:", src)
            
            response = requests.get(src, headers=header)
            data = response.text
            soup = BeautifulSoup(data, "html.parser")
            scripts = soup.find_all('script')
            
            # find the second link of iframe, note [:-6] to remove the last 6 characters
            # print(scripts)
                ## print iframe src attribute that contains the specific path
            for script in scripts:
                src = script.get('src', '')
                if "https://fast.wistia.com/embed/medias/" in src:
                    print("Second Iframe URL:", src[:-6])

                    response2 = requests.get(src[:-6], headers=header)
                    data2 = response2.text
                    # print(data2)
                    # soup2 = BeautifulSoup(data2, "html_parser")
                    # scripts2 = soup2.find_all('script')
                    
                    # for script in scripts2:
                    # Step 1: Extract JavaScript
                    pattern = re.compile(r'W\.embed\((.*?)\, embedOptions\);', re.DOTALL)
                    match = re.search(pattern, data2)

                    if match:
                        js_str = match.group(1)
                        
                        # Step 2: Clean Up JavaScript
                        js_str_clean = js_str.replace('\'', '\"')  # Replace single quotes with double quotes.
                        js_str_clean = re.sub(r'(?<=[{,])\s*([^":\s]+)\s*:', r'"\1":', js_str_clean)  # Add double quotes around property names
                        
                        try:
                            # Step 3: Convert to JSON
                            js_data = json.loads(js_str_clean)
                            
                            # Step 4: take the original resolution
                            # Initialize variable to store the desired URL
                            desired_url = None
                            # Loop through assets
                            for asset in js_data['assets']:
                                if asset['type'] == 'original':
                                    desired_url = asset['url']
                                    break  # Stop the loop once the desired type is found
                            
                            # Step 5: Replace .bin with .mp4
                            if desired_url:
                                desired_url_mp4 = desired_url.replace('.bin', '.mp4')
                                print(f"Found URL with desired type (original): {desired_url_mp4}")
                                print(desired_url_mp4)
                                
                                ### download video
                                ### there are other contexts before 38 and after 35
                                filename = titles[38:-34][clip -1].split("\n")[0].replace(",", "").replace(".",'')
                                output_filename = f"{filename}.mp4"  # Save to /mnt/data so you can retrieve the file from the session
                                response = requests.get(desired_url_mp4, stream=True)

                                # Check if the request was successful (HTTP Status Code 200)
                                if response.status_code == 200:
                                    with open(output_filename, 'wb') as output_file:
                                        for chunk in response.iter_content(chunk_size=1024):
                                            if chunk:
                                                output_file.write(chunk)
                                    print("Download complete!")
                                
                                    # convert into audio file    
                                    # Insert Local Video File Path
                                    clip = mp.VideoFileClip(f"{output_filename}")
                                    
                                    # Insert Local Audio File Path
                                    clip.audio.write_audiofile(f"{output_filename[:-4]}.mp3")
                                
                                
                                
                                else:
                                    print(f"Failed to download video. Status code: {response.status_code}")
                                    
                                    
                            else:
                                print("No URL found with the desired type (original).")
                        except json.JSONDecodeError as e:
                            print("Failed to decode JSON.")
                            print("Error:", str(e))
                    else:
                        print("Pattern did not match.")
